{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORvbBPY9un2+asch4YSE+g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Step By Step"],"metadata":{"id":"4f0fugzQz-Gn"}},{"cell_type":"code","source":["# Clone the library\n","!git clone https://github.com/thuml/Time-Series-Library\n","# Switch working directory to the imported one\n","%cd '/content/Time-Series-Library'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buRHiKN309G_","executionInfo":{"status":"ok","timestamp":1715788265398,"user_tz":-120,"elapsed":9,"user":{"displayName":"Bálint Nagy","userId":"14093698352506872760"}},"outputId":"dba3c3d9-ab86-4859-9b7e-0c5158e9b3de"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'Time-Series-Library' already exists and is not an empty directory.\n","/content/Time-Series-Library\n"]}]},{"cell_type":"code","source":["# Install all requirements\n","!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4bDQ2qr0cce","executionInfo":{"status":"ok","timestamp":1715788333978,"user_tz":-120,"elapsed":8530,"user":{"displayName":"Bálint Nagy","userId":"14093698352506872760"}},"outputId":"f539888e-435a-4804-c0c8-d1510150534b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops==0.4.0 (from -r requirements.txt (line 1))\n","  Using cached einops-0.4.0-py3-none-any.whl (28 kB)\n","Collecting matplotlib==3.7.0 (from -r requirements.txt (line 2))\n","  Using cached matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n","Collecting numpy==1.23.5 (from -r requirements.txt (line 3))\n","  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","Collecting pandas==1.5.3 (from -r requirements.txt (line 4))\n","  Using cached pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n","Collecting patool==1.12 (from -r requirements.txt (line 5))\n","  Using cached patool-1.12-py2.py3-none-any.whl (77 kB)\n","Collecting reformer-pytorch==1.4.4 (from -r requirements.txt (line 6))\n","  Using cached reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.2.2)\n","Collecting scipy==1.10.1 (from -r requirements.txt (line 8))\n","  Using cached scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n","Collecting sktime==0.16.1 (from -r requirements.txt (line 9))\n","  Using cached sktime-0.16.1-py3-none-any.whl (16.0 MB)\n","Collecting sympy==1.11.1 (from -r requirements.txt (line 10))\n","  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n","\u001b[31mERROR: Ignored the following versions that require a different python version: 0.10.0 Requires-Python >=3.7,<3.10; 0.10.1 Requires-Python >=3.7,<3.10; 0.11.0 Requires-Python >=3.7,<3.10; 0.11.1 Requires-Python >=3.7,<3.10; 0.11.2 Requires-Python >=3.7,<3.10; 0.11.3 Requires-Python >=3.7,<3.10; 0.11.4 Requires-Python >=3.7,<3.10; 0.12.0 Requires-Python >=3.7,<3.10; 0.12.1 Requires-Python >=3.7,<3.10; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1cx0EKNP7njM","executionInfo":{"status":"ok","timestamp":1715788272355,"user_tz":-120,"elapsed":11,"user":{"displayName":"Bálint Nagy","userId":"14093698352506872760"}},"outputId":"b891830c-d2cb-4676-bcc5-aa0a3b59ef99"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Time-Series-Library\n"]}]},{"cell_type":"code","source":["#%cd '/content'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWVyMtyc8B1E","executionInfo":{"status":"ok","timestamp":1715788084632,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bálint Nagy","userId":"14093698352506872760"}},"outputId":"850a6b98-1094-4ef0-81d1-00a783bbe1a3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["# Import necessary packages\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.fft\n","from layers.Embed import DataEmbedding\n","from layers.Conv_Blocks import Inception_Block_V1  # For now, I stay with inception block"],"metadata":{"id":"Q7TZ2mW01Lv7","executionInfo":{"status":"ok","timestamp":1715788093585,"user_tz":-120,"elapsed":249,"user":{"displayName":"Bálint Nagy","userId":"14093698352506872760"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Creating TimesBlock\n","class TimesBlock(nn.Module):\n","    def __init__(self, configs):    ##configs is the configuration defined for TimesBlock\n","        super(TimesBlock, self).__init__()\n","        self.seq_len = configs.seq_len   ##sequence length\n","        self.pred_len = configs.pred_len ##prediction length\n","        self.k = configs.top_k    ##k denotes how many top frequencies are\n","                                                                #taken into consideration\n","        # parameter-efficient design\n","        self.conv = nn.Sequential(\n","            Inception_Block_V1(configs.d_model, configs.d_ff,\n","                              num_kernels=configs.num_kernels),\n","            nn.GELU(),\n","            Inception_Block_V1(configs.d_ff, configs.d_model,\n","                              num_kernels=configs.num_kernels)\n","        )\n","    def forward(self, x):\n","            B, T, N = x.size()\n","                #B: batch size  T: length of time series  N:number of features\n","            period_list, period_weight = FFT_for_Period(x, self.k)\n","                #FFT_for_Period() will be shown later. Here, period_list([top_k]) denotes\n","                #the top_k-significant period and period_weight([B, top_k]) denotes its weight(amplitude)\n","\n","            res = []\n","            for i in range(self.k):\n","                period = period_list[i]\n","\n","                # padding : to form a 2D map, we need total length of the sequence, plus the part\n","                # to be predicted, to be divisible by the period, so padding is needed\n","                if (self.seq_len + self.pred_len) % period != 0:\n","                    length = (\n","                                    ((self.seq_len + self.pred_len) // period) + 1) * period\n","                    padding = torch.zeros([x.shape[0], (length - (self.seq_len + self.pred_len)), x.shape[2]]).to(x.device)\n","                    out = torch.cat([x, padding], dim=1)\n","                else:\n","                    length = (self.seq_len + self.pred_len)\n","                    out = x\n","\n","                # reshape: we need each channel of a single piece of data to be a 2D variable,\n","                # Also, in order to implement the 2D conv later on, we need to adjust the 2 dimensions\n","                # to be convolutioned to the last 2 dimensions, by calling the permute() func.\n","                # Whereafter, to make the tensor contiguous in memory, call contiguous()\n","                out = out.reshape(B, length // period, period,\n","                                  N).permute(0, 3, 1, 2).contiguous()\n","\n","                #2D convolution to grap the intra- and inter- period information\n","                out = self.conv(out)\n","\n","                # reshape back, similar to reshape\n","                out = out.permute(0, 2, 3, 1).reshape(B, -1, N)\n","\n","                #truncating down the padded part of the output and put it to result\n","                res.append(out[:, :(self.seq_len + self.pred_len), :])\n","            res = torch.stack(res, dim=-1) #res: 4D [B, length , N, top_k]\n","\n","            # adaptive aggregation\n","            #First, use softmax to get the normalized weight from amplitudes --> 2D [B,top_k]\n","            period_weight = F.softmax(period_weight, dim=1)\n","\n","            #after two unsqueeze(1),shape -> [B,1,1,top_k],so repeat the weight to fit the shape of res\n","            period_weight = period_weight.unsqueeze(\n","                1).unsqueeze(1).repeat(1, T, N, 1)\n","\n","            #add by weight the top_k periods' result, getting the result of this TimesBlock\n","            res = torch.sum(res * period_weight, -1)\n","\n","            # residual connection\n","            res = res + x\n","            return res"],"metadata":{"id":"EYwQXVT_3yG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FFT definition\n","def FFT_for_Period(x, k=2):\n","    # xf shape [B, T, C], denoting the amplitude of frequency(T) given the datapiece at B,N\n","    xf = torch.fft.rfft(x, dim=1)\n","\n","    # find period by amplitudes: here we assume that the periodic features are basically constant\n","    # in different batch and channel, so we mean out these two dimensions, getting a list frequency_list with shape[T]\n","    # each element at pos t of frequency_list denotes the overall amplitude at frequency (t)\n","    frequency_list = abs(xf).mean(0).mean(-1)\n","    frequency_list[0] = 0\n","\n","    #by torch.topk(),we can get the biggest k elements of frequency_list, and its positions(i.e. the k-main frequencies in top_list)\n","    _, top_list = torch.topk(frequency_list, k)\n","\n","    #Returns a new Tensor 'top_list', detached from the current graph.\n","    #The result will never require gradient.Convert to a numpy instance\n","    top_list = top_list.detach().cpu().numpy()\n","\n","    #period:a list of shape [top_k], recording the periods of mean frequencies respectively\n","    period = x.shape[1] // top_list\n","\n","    #Here,the 2nd item returned has a shape of [B, top_k],representing the biggest top_k amplitudes\n","    # for each piece of data, with N features being averaged.\n","    return period, abs(xf).mean(-1)[:, top_list]"],"metadata":{"id":"rhVZy4WL4Fjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating the model without unnecessary blocks\n","class Model(nn.Module):\n","    def __init__(self, configs):\n","      super(Model, self).__init__()\n","      #params init\n","      self.configs = configs\n","      self.task_name = configs.task_name\n","      self.seq_len = configs.seq_len\n","      self.label_len = configs.label_len\n","      self.pred_len = configs.pred_len\n","\n","      #stack TimesBlock for e_layers times to form the main part of TimesNet, named model\n","      self.model = nn.ModuleList([TimesBlock(configs)\n","                                  for _ in range(configs.e_layers)])\n","\n","      #embedding & normalization\n","      # enc_in is the encoder input size, the number of features for a piece of data\n","      # d_model is the dimension of embedding\n","      self.enc_embedding = DataEmbedding(configs.enc_in, configs.d_model, configs.embed, configs.freq,\n","                                        configs.dropout)\n","      self.layer = configs.e_layers # num of encoder layers\n","      self.layer_norm = nn.LayerNorm(configs.d_model)\n","\n","      #define the some layers for different tasks\n","      if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n","          self.predict_linear = nn.Linear(\n","              self.seq_len, self.pred_len + self.seq_len)\n","          self.projection = nn.Linear(\n","              configs.d_model, configs.c_out, bias=True)\n","\n","\n","    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n","        # Normalization from Non-stationary Transformer at temporal dimension\n","        means = x_enc.mean(1, keepdim=True).detach() #[B,T]\n","        x_enc = x_enc - means\n","        stdev = torch.sqrt(\n","            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n","        x_enc /= stdev\n","\n","        # embedding: projecting a number to a C-channel vector\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)  # [B,T,C] C is d_model\n","        enc_out = self.predict_linear(enc_out.permute(0, 2, 1)).permute(\n","            0, 2, 1)  # align temporal dimension [B,pred_len+seq_len,C]\n","\n","        # TimesNet: pass through TimesBlock for self.layer times each with layer normalization\n","        for i in range(self.layer):\n","            enc_out = self.layer_norm(self.model[i](enc_out))\n","\n","        # project back  #[B,T,d_model]-->[B,T,c_out]\n","        dec_out = self.projection(enc_out)\n","\n","        # De-Normalization from Non-stationary Transformer\n","        dec_out = dec_out * \\\n","                  (stdev[:, 0, :].unsqueeze(1).repeat(\n","                      1, self.pred_len + self.seq_len, 1)) #lengthen the stdev to fit the dec_out\n","        dec_out = dec_out + \\\n","                  (means[:, 0, :].unsqueeze(1).repeat(\n","                      1, self.pred_len + self.seq_len, 1)) #lengthen the mean to fit the dec_out\n","        return dec_out"],"metadata":{"id":"HWQC0qBW3Jfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os"],"metadata":{"id":"XtjGc_OC2Ok0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(self, setting):  #setting is the args for this model training\n","    #get train dataloader\n","    train_data, train_loader = self._get_data(flag='train')\n","    vali_data, vali_loader = self._get_data(flag='val')\n","    test_data, test_loader = self._get_data(flag='test')\n","\n","    # set path of checkpoint for saving and loading model\n","    path = os.path.join(self.args.checkpoints, setting)\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","    time_now = time.time()\n","\n","    train_steps = len(train_loader)\n","\n","    # EarlyStopping is typically a custom class or function that monitors the performance\n","    # of a model during training, usually by tracking a certain metric (commonly validation\n","    # loss or accuracy).It's a common technique used in deep learning to prevent overfitting\n","    # during the training\n","    early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n","\n","    #Optimizer and Loss Function Selection\n","    model_optim = self._select_optimizer()\n","    criterion = self._select_criterion()\n","\n","    # AMP training is a technique that uses lower-precision data types (e.g., float16)\n","    # for certain computations to accelerate training and reduce memory usage.\n","    if self.args.use_amp:\n","        scaler = torch.cuda.amp.GradScaler()\n","    for epoch in range(self.args.train_epochs):\n","        iter_count = 0\n","        train_loss = []\n","        self.model.train()\n","        epoch_time = time.time()\n","\n","        #begin training in this epoch\n","        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n","            iter_count += 1\n","            model_optim.zero_grad()\n","            batch_x = batch_x.float().to(self.device)  #input features\n","            batch_y = batch_y.float().to(self.device)  #target features\n","\n","            # _mark holds information about time-related features. Specifically, it is a\n","            # tensor that encodes temporal information and is associated with the\n","            # input data batch_x.\n","            batch_x_mark = batch_x_mark.float().to(self.device)\n","            batch_y_mark = batch_y_mark.float().to(self.device)\n","            # decoder input(didn't use in TimesNet case)\n","            dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n","            dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n","            # encoder - decoder\n","            if self.args.use_amp: #in the case of TimesNet, use_amp should be False\n","                with torch.cuda.amp.autocast():\n","                    # whether to output attention in ecoder,in TimesNet case is no\n","                    if self.args.output_attention:\n","                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                    # model the input\n","                    else:\n","                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","\n","                    # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate,\n","                    # S:univariate predict univariate, MS:multivariate predict univariate'\n","                    #if multivariate predict univariate',then output should be the last column of the decoder\n","                    # output, so f_dim = -1 to only contain the last column, else is all columns\n","                    f_dim = -1 if self.args.features == 'MS' else 0\n","                    outputs = outputs[:, -self.args.pred_len:, f_dim:]\n","                    batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n","\n","                    # calc loss\n","                    loss = criterion(outputs, batch_y)\n","                    train_loss.append(loss.item())\n","            else:  #similar to when use_amp is True\n","                if self.args.output_attention:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n","                else:\n","                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","                f_dim = -1 if self.args.features == 'MS' else 0\n","                outputs = outputs[:, -self.args.pred_len:, f_dim:]\n","                batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n","                loss = criterion(outputs, batch_y)\n","                train_loss.append(loss.item())\n","\n","            # When train rounds attain some 100-multiple, print speed, left time, loss. etc feedback\n","            if (i + 1) % 100 == 0:\n","                print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                speed = (time.time() - time_now) / iter_count\n","                left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n","                print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                iter_count = 0\n","                time_now = time.time()\n","\n","            #BP\n","            if self.args.use_amp:\n","                scaler.scale(loss).backward()\n","                scaler.step(model_optim)\n","                scaler.update()\n","            else:\n","                loss.backward()\n","                model_optim.step()\n","\n","        #This epoch comes to end, print information\n","        print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n","        train_loss = np.average(train_loss)\n","\n","        #run test and validation on current model\n","        vali_loss = self.vali(vali_data, vali_loader, criterion)\n","        test_loss = self.vali(test_data, test_loader, criterion)\n","\n","        #print train, test, vali loss information\n","        print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n","            epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n","\n","        #Decide whether to trigger Early Stopping. if early_stop is true, it means that\n","        #this epoch's training is now at a flat slope, so stop further training for this epoch.\n","        early_stopping(vali_loss, self.model, path)\n","        if early_stopping.early_stop:\n","            print(\"Early stopping\")\n","            break\n","\n","        #adjust learning keys\n","        adjust_learning_rate(model_optim, epoch + 1, self.args)\n","    best_model_path = path + '/' + 'checkpoint.pth'\n","\n","    # loading the trained model's state dictionary from a saved checkpoint file\n","    # located at best_model_path.\n","    self.model.load_state_dict(torch.load(best_model_path))\n","    return self.model"],"metadata":{"id":"zm0ZUszG4dgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EarlyStopping:\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        self.patience = patience # how many times will you tolerate for loss not being on decrease\n","        self.verbose = verbose  # whether to print tip info\n","        self.counter = 0 # now how many times loss not on decrease\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model, path):\n","        score = -val_loss\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","\n","        # meaning: current score is not 'delta' better than best_score, representing that\n","        # further training may not bring remarkable improvement in loss.\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            # 'No Improvement' times become higher than patience --> Stop Further Training\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","\n","        else: #model's loss is still on decrease, save the now best model and go on training\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model, path)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model, path):\n","    ### used for saving the current best model\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), path + '/' + 'checkpoint.pth')\n","        self.val_loss_min = val_loss"],"metadata":{"id":"07Vhd57C5jGF"},"execution_count":null,"outputs":[]}]}